% Created 2016-07-13 mié 20:28
\documentclass[11pt,letterpaper]{article}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{xltxtra}
\usepackage[top=2.0cm, bottom=3cm, left=2.0cm, right=2.0cm]{geometry}
\author{Juan Ávalo, Bastien Got}
\date{\today}
\title{Tarea 3 Análisis Inteligente de Datos}
\hypersetup{
 pdfauthor={Juan Ávalo, Bastien Got},
 pdftitle={Tarea 3 Análisis Inteligente de Datos},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.1.50.2 (Org mode 8.3.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Reconocimiento de Texto}
\label{sec:orgheadline1}

\begin{enumerate}
\item Tanto el set de entrenamiento como el de pruebas tienen \textbf{3554} datos.
Los datos se separan en textos positivos y negativos de acuerdo a la tabla:
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Sets & Positivos & Negativos\\
\hline
Entrenamiento & 1770 & 1784\\
Prueba & 1803 & 1751\\
\hline
\end{tabular}
\end{center}
\item Se creó una función que extrae palabras usando \emph{stemming} y quitando
\emph{stopwords} si así es pedido. Sobre los resultados obtenidos se puede
observar con los ejemplos usados que \emph{stemming} lo que hace es hacer que
una palabra tome una pseudoraiz. Además, el proceso de quitar \emph{stopwords}
efectivamente quita palabras como "I" o "to".

Como ejemplo, las frases: "I love to eat cake" y "I love eating cake" ambas
se reducen a "love", "eat" y "cake".

Pero un ejemplo más interesante es el de aplicar \emph{stemming} sobre palabras
como "absolutely" y "dislike", las cuales se traducen en "absolut" y
"dislik". Ninguna de las pseudoraices es una palabra del inglés verdadera,
pero van a ser útiles para saber que palabras están relacionadas o no.
\item También se creó una función análoga a la del punto anterior, pero
lematizando. Para poder lograr ésto no se pudo usar la función
\texttt{WordNetLemmatizer} directamente como estaba en los ejemplos.

Lematización involucra hacer un análisis sintáctico de las palabras, por lo
que la función usada pide marcar cada palabra con la posición dentro de la
oración que tiene (verbo, sustantivo, adjetivo, adverbio), la cual se
obtuvo mediante la función \texttt{pos\_tag}.

Los efectos en las palabras de ejemplo son aparentes. En casos como el de
"I love to eat cake" el lematizador las reduce de la misma forma que usando
\emph{stemming}. La diferencia se nota al usar las palabras "dislike" y
"absolutely", las cuales se mantienen iguales. O con palabras como "are" e
"is" las cuales se reducen a "to be".
\item Se generaron cuatro representaciones vectoriales para los dos conjuntos de
datos. La razón de ésto es porque se necesita extraer palabras con
\emph{stemming} y con \emph{lemmatize}, con \emph{stopwords} y sin ellas.

La representación del texto consiste en resumir cada comentario a un vector
binario con todo el vocabulario obtenido de todos los mensajes. Si el
mensaje tiene una palabra dentro del vocabulario, el valor de la variable
correspondiente a esa palabra es \textbf{1}. Sino es \textbf{0}. 

Luego las etiquetas son \textbf{0} si el mensaje es negativo, y \textbf{1} si es
positivo.

Considerando como se tratan los datos, se puede rankear las palabras que
globálmente se encontraron por frecuencia. Un ejemplo de ello es la
siguiente tabla:

\begin{center}
\begin{tabular}{|c|c|}
Frecuencia & Palabra\\
\hline
115 & way\\
125 & get\\
127 & well\\
128 & much\\
129 & work\\
143 & even\\
143 & time\\
145 & comedy\\
163 & character\\
169 & good\\
176 & story\\
246 & one\\
254 & like\\
264 & make\\
481 & movie\\
573 & film\\
\hline
\end{tabular}
\end{center}
\item El evaluador de desempeño considera las siguientes medidas:
\begin{itemize}
\item La precisión del modelo sobre los datos de entrenamiento.
\item La precisión del modelo sobre los datos de prueba.
\item La \emph{precisión}, esto es, el porcentaje de datos bien clasificados dentro de
todos los datos clasificados.
\item El \emph{recall} el cual es el porcentaje de los datos seleccionados bien
clasificados dentro de los datos de su clase.
\item El \emph{f1-score}, el cual es la media armónica entre la precisión y el
recall.
\item El support, que cuenta cuantos datos de cada clase hay.
\end{itemize}
\item Se creó la función para ajustar un modelo \emph{Naive Bayesian} sobre los datos.
\end{enumerate}
\end{document}